{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f22df824-7344-41e0-84fb-e5b7e5550a76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path = \"/Workspace/Users/a845678@asb.dtcbtndsie.onmicrosoft.com/assignment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b61e7d3-eb4f-4fbf-9dc0-3fb2867af60d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Stores-silver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d172286-1316-4404-af57-388b99f23807",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "\n",
    "# Step 1: Load the JSON file into a pandas DataFrame\n",
    "input_path = f\"{path}/data_storage/1_bronze/src_stores/bronze_stores.json\"\n",
    "output_path = f\"{path}/data_storage/2_silver/silver_stores\"\n",
    "file_name = \"stores\"\n",
    "\n",
    "data = pd.read_json(input_path)\n",
    "\n",
    "# Flatten the locales data\n",
    "flattened_data = []\n",
    "for index, row in data.iterrows():\n",
    "    id, lat, lng, locales = row[\"id\"], row[\"lat\"], row[\"lng\"], row[\"locales\"]\n",
    "    for locale_key, locale_value in locales.items():\n",
    "        entry = {\n",
    "            \"id\": id,\n",
    "            \"lat\": lat,\n",
    "            \"lng\": lng,\n",
    "            \"locale\": locale_key,\n",
    "            \"displayName\": locale_value[\"displayName\"],\n",
    "            \"displayNameAlternate\": locale_value[\"displayNameAlternate\"],\n",
    "            \"street\": locale_value[\"address\"].get(\"street\"),\n",
    "            \"zipCode\": locale_value[\"address\"].get(\"zipCode\"),\n",
    "            \"city\": locale_value[\"address\"].get(\"city\"),\n",
    "            \"timezone\": locale_value[\"address\"].get(\"timezone\"),\n",
    "            \"stateProvinceCode\": locale_value[\"address\"].get(\"stateProvinceCode\"),\n",
    "            \"displayAddress\": locale_value[\"address\"].get(\"displayAddress\"),\n",
    "        }\n",
    "        flattened_data.append(entry)\n",
    "\n",
    "# Create a new DataFrame from the flattened data\n",
    "df_flattened = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Step 3: Drop duplicates\n",
    "silver_stores = df_flattened.drop_duplicates()\n",
    "\n",
    "# Step 4: Save as CSV\n",
    "silver_stores.to_csv(f\"{output_path}/silver_{file_name}.csv\", index=False)\n",
    "\n",
    "print(f\"CSV file saved successfully at {output_path}/silver_{file_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f2d31c3-ce88-477f-b84b-ea07804efef0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Big-mac-silver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75d7b0fd-ba2f-4d25-8a01-e0c5cf8eb642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "input_path = f\"{path}/data_storage/1_bronze/src_economist\"\n",
    "output_path = f\"{path}/data_storage/2_silver/silver_economist\"\n",
    "file_name = \"big-mac-data\"\n",
    "\n",
    "batch_paths = [\n",
    "    f\"{input_path}/batch_1/big-mac-source-data-v2_1.csv\",\n",
    "    f\"{input_path}/batch_2/big-mac-source-data-v2_2.csv\",\n",
    "    f\"{input_path}/batch_3/big-mac-source-data-v2_3.csv\",\n",
    "]\n",
    "spark = SparkSession.builder.appName(\"Example\").getOrCreate()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"iso_a3\", StringType(), True),\n",
    "    StructField(\"currency_code\", StringType(), True),\n",
    "    StructField(\"local_price\", DoubleType(), True),\n",
    "    StructField(\"dollar_ex\", DoubleType(), True),\n",
    "    StructField(\"GDP_dollar\", DoubleType(), True),\n",
    "    StructField(\"GDP_local\", DoubleType(), True),\n",
    "    StructField(\"date\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create empty spark dataframe with specified schema to which we will append each batch\n",
    "silver_big_mac = spark.createDataFrame(data=[], schema=schema)\n",
    "\n",
    "for path in batch_paths:\n",
    "    \n",
    "    raw_data = pd.read_csv(path)\n",
    "\n",
    "    # Convert Pandas DataFrame to PySpark DataFrame\n",
    "    raw_data = spark.createDataFrame(raw_data)\n",
    "\n",
    "    # Apply transformations\n",
    "    cleaned_data = raw_data.dropDuplicates()\n",
    "    \n",
    "    # Append data\n",
    "    silver_big_mac = silver_big_mac.union(cleaned_data)\n",
    "\n",
    "# Write to Silver layer\n",
    "silver_big_mac.toPandas().to_csv(f\"{output_path}/silver_{file_name}.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_layer.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
